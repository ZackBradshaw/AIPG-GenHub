worker_config:
  exec_type: it
  ports: "443:443"
  network: ai_network
  container_name: worker
  image_name: worker-image

aphrodite_config:
  exec_type: it
  ports: "2242:7860"
  network: ai_network
  container_name: aphrodite-engine
  gpus: "all"
  shm-size: "8g"
  env:
    - MODEL_NAME=meta-llama/Meta-Llama-3-8B-Instruct #or use TheBloke/Mistral-7B-v0.1-GPTQ #See list of models supported, take note of required VRAM
    - KOBOLD_API=true
    - GPU_MEMORY_UTILIZATION=0.8 #If you are running out of memory, consider decreasing this value
    - HF_TOKEN=hf_****  #Your hugging face token, If you are using a gated model like llama 3.
  image_name: alpindale/aphrodite-engine
